{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3L0QfLOCeuIZ",
    "outputId": "d740718e-ca66-4582-8880-47185bb13a62",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4YiCOp9fH8O",
    "outputId": "3a5cca34-45a6-4fef-9100-e33a2d68c7ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install required packages.\n",
    "#!pip install progress progressbar2 alive-progress tqdm\n",
    "#!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "#!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "# !pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "#!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-2.3.1+cu121.html\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbRJGVSKTI2O",
    "outputId": "c7de89c2-11b1-4d11-d05d-e24472fffd3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple progress progressbar2 alive-progress tqdm\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch-scatter -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch-sparse -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch-cluster -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch-spline-conv -f https://pytorch-geometric.com/whl/torch-2.4.0+cu121.html\n",
    "#!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "CzZTOdACe1T7",
    "outputId": "e1bc7d13-32c8-4c8d-f743-376cd8625737",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# XXX: only one GPU on Colab and isn’t guaranteed\\ngpu = GPUs[0]\\ndef printm():\\n  process = psutil.Process(os.getpid())\\n  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\\n  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\\n\\nprintm()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory footprint support libraries/code\n",
    "#!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "#!pip install gputil\n",
    "#!pip install psutil\n",
    "#!pip install humanize\n",
    "\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "#import GPU as GPU\n",
    "#GPUs = GPU.getGPUs()\n",
    "'''\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "\n",
    "printm()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FHtLXjv9e303",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import os, glob\n",
    "import time\n",
    "import h5py\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import ConcatDataset, Dataset, DataLoader, sampler, DistributedSampler\n",
    "#from torch.utils.data import *\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y38NL2j8e59u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=5, help='Number of epochs to train.')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='Initial learning rate.') #100\n",
    "parser.add_argument('--maxnodes', type=int, default=1000, help='max nodes.') #100\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.') #0.001\n",
    "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout rate (1 - keep probability).')\n",
    "args = parser.parse_args([])\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JGhyb1h3e705",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "class ParquetDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.parquet = pq.ParquetFile(filename)\n",
    "        self.cols = None # read all columns\n",
    "        #self.cols = ['X_jets.list.item.list.item.list.item','y']\n",
    "    def __getitem__(self, index):\n",
    "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
    "        #print(data.keys())\n",
    "        data['X_jet'] = torch.tensor(np.float32(data['X_jet']))\n",
    "        data['y'] = torch.tensor(np.float32(data['y']))\n",
    "        #data['m0'] = torch.tensor(np.float32(data['m0']))\n",
    "        #data['pt'] = torch.tensor(np.float32(data['pt']))\n",
    "        data['X_jet'][data['X_jet'] < 1.e-3] = 0.\n",
    "        # Preprocessing\n",
    "        #data['nonzeroPixels'][data['nonzeroPixels'] < 1.e-3] = 0. # Zero-Suppression\n",
    "        #data['nonzeroPixels'][-1,...] = 25.*data['nonzeroPixels'][-1,...] # For HCAL: to match pixel intensity distn of other layers\n",
    "        #data['nonzeroPixels'] = data['nonzeroPixels']/100. # To standardize\n",
    "        return dict(data)\n",
    "    def __len__(self):\n",
    "        return self.parquet.num_row_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaE_b2x68iW2",
    "outputId": "70d142d2-47a8-46dd-98b3-f0507d112bc5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toal files   1\n"
     ]
    }
   ],
   "source": [
    "# Boosted Top Jets\n",
    "decays = sorted(glob.glob('/pscratch/sd/b/bbbam/IMG_aToTauTau_Hadronic_tauDR0p4_m1p2To3p6_m14p8To17p2_dataset_2_unbaised_v2_train/*m1p2To3p6*0000*'))\n",
    "print(\"toal files  \", len(decays))               \n",
    "\n",
    "dset_train = ConcatDataset([ParquetDataset(d) for d in decays])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uTg5rltafS0l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## generate list to count nodes for each graph\n",
    "def nodeCounter(samples):\n",
    "    inds=[]\n",
    "    for k in samples:\n",
    "        inds.append(k['x'].shape[0])\n",
    "    return inds\n",
    "\n",
    "def ref(bsize,nodeC,i1,i2):\n",
    "  maxC=np.max(np.array(nodeC))\n",
    "  maxC=args.maxnodes#maxC + (4 - maxC % 4) ##max num of nodes 1161%4\n",
    "  refMat=np.zeros((bsize,maxC)) ## matrix of zeros\n",
    "  for pi in range(i1,i2):##10\n",
    "    refMat[pi,:nodeC[pi]]=1 ## fill ones\n",
    "  return refMat,maxC\n",
    "\n",
    "def assigner(nodelist):\n",
    "  fin=[]\n",
    "  countit=0\n",
    "  for m in nodelist:\n",
    "      fin.append(np.repeat(countit,m))\n",
    "      countit+=1\n",
    "  return np.array(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6S1n71kKtP77",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ApsgTc5bgCsD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Boosted Top Jets without GPU\n",
    "import torch_geometric.transforms\n",
    "from torch_geometric.nn import knn_graph\n",
    "import torch_geometric.data\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import progressbar\n",
    "from progressbar import Bar\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def progress(value, max=3200):\n",
    "    return HTML(\"\"\"\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 75%'\n",
    "        >\n",
    "            {value}\n",
    "        </progress>\n",
    "    \"\"\".format(value=value, max=max))\n",
    "\n",
    "def convert_to_graph(train_data, start_idx, end_idx, granularity=1, new_file=False):   # input data format should be [N,C,H,W]\n",
    "    print('Processing idx nos. from '+str(start_idx)+' to '+str(end_idx))\n",
    "    out = display(progress(start_idx, end_idx), display_id=True)\n",
    "    for idx in range(start_idx,end_idx):\n",
    "\n",
    "      data=train_data[idx]['X_jet']\n",
    "      min_pixel_val = torch.min(data)\n",
    "      max_pixel_val = torch.max(data)\n",
    "      image3D = data.reshape(125*granularity,125*granularity,13)\n",
    "      Hcal_frame = torch.zeros_like(image3D[:,:,4])\n",
    "      for i in range(0,image3D.shape[0]):\n",
    "        for j in range(0,image3D.shape[1]):\n",
    "          if (i-2)%5 == 0:\n",
    "            if (j-2)%5 == 0:\n",
    "              Hcal_frame[i,j] = torch.sum(image3D[i-2:i+3,j-2:j+3,4])\n",
    "            else:\n",
    "              Hcal_frame[i,j] = 0.\n",
    "          else:\n",
    "            Hcal_frame[i,j] = 0.\n",
    "      image3D[:,:,4] = Hcal_frame\n",
    "      nonzero_pos = torch.nonzero(image3D, as_tuple=True)\n",
    "      coords = torch.cat((torch.unsqueeze(nonzero_pos[0],dim=1), torch.unsqueeze(nonzero_pos[1],dim=1)),dim=1).float()\n",
    "      coords = (coords.float() - 62)/62\n",
    "\n",
    "      Ecal = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],3],dim=1)\n",
    "      dz = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],2],dim=1)\n",
    "      d0 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],1],dim=1)\n",
    "      Hcal = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],4],dim=1)\n",
    "      pT = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],0],dim=1)\n",
    "      BPIX1 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],5],dim=1)\n",
    "      BPIX2 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],6],dim=1)\n",
    "      BPIX3 = torch.unsqueeze(image3D[nonzero_pos[0],nonzero_pos[1],7],dim=1)\n",
    "      feats = torch.cat((coords[:,0:1],coords[:,1:], pT, d0, dz, Ecal, Hcal, BPIX1, BPIX2, BPIX3), dim=1)\n",
    "      feats = torch.unique(feats,dim=0)\n",
    "      edge_index = knn_graph(feats[:,0:2], k=16, batch=None, loop=True)  ## Create knn graph adjacency matrix\n",
    "      #print(coords.shape, edge_index.shape, pT.shape, Ecal.shape, Hcal.shape, dz.shape, d0.shape, BPIX1.shape, BPIX2.shape, BPIX3.shape)\n",
    "\n",
    "      #parquet_Dataframe = pd.DataFrame({'coords0':[np.array(coords[:,0].cpu())], 'coords1':[np.array(coords[:,1].cpu())], 'edge_index_from': [np.array(edge_index[0,:].cpu())], 'edge_index_to': [np.array(edge_index[1,:].cpu())], 'pT': [np.array(torch.squeeze(pT).cpu())], 'ECAL':[np.array(torch.squeeze(Ecal).cpu())], 'HCAL':[np.array(torch.squeeze(Hcal).cpu())], 'd0':[np.array(torch.squeeze(d0).cpu())], 'dz':[np.array(torch.squeeze(dz).cpu())], 'BPIX1':[np.array(torch.squeeze(BPIX1).cpu())], 'BPIX2': [np.array(torch.squeeze(BPIX2).cpu())], 'BPIX3': [np.array(torch.squeeze(BPIX3).cpu())], 'y':np.array(train_data[idx]['y']), 'tfrecord': train_data[idx]['tfrecord'], 'm0': train_data[idx]['m0'], 'pT_jet': train_data[idx]['pt']})\n",
    "      parquet_Dataframe = pd.DataFrame({'coords0':[np.array(feats[:,0].cpu())],'coords1':[np.array(feats[:,1].cpu())],'edge_index_from': [np.array(edge_index[0,:].cpu())],'edge_index_to': [np.array(edge_index[1,:].cpu())],'pT':[np.array(feats[:,2].cpu())],'d0':[np.array(feats[:,3].cpu())],'dz':[np.array(feats[:,4].cpu())],'ECAL':[np.array(feats[:,5].cpu())],'HCAL':[np.array(feats[:,6].cpu())],'BPIX1':[np.array(feats[:,7].cpu())],'BPIX2':[np.array(feats[:,8].cpu())],'BPIX3':[np.array(feats[:,9].cpu())],'y':np.array(train_data[idx]['y']), 'tfrecord': train_data[idx]['tfrecord'], 'm0': train_data[idx]['m0'], 'pT_jet': train_data[idx]['pt']})\n",
    "      table = pa.Table.from_pandas(parquet_Dataframe)\n",
    "      #print(type(table.schema), type(table))\n",
    "\n",
    "      if (new_file):\n",
    "      # create a parquet write object giving it an output file\n",
    "        output_filename = 'data_shared/BoostedTopParquet_x1_fixed_Graphs/BoostedTop_x1_train_samples_'+str(start_idx)+'_to_'+str(end_idx-1)+'.parquet'\n",
    "        pqwriter = pq.ParquetWriter(output_filename,table.schema,compression='snappy')\n",
    "        new_file=False\n",
    "      pqwriter.write_table(table)\n",
    "      out.update(progress(idx, end_idx))\n",
    "      if (idx%10==0):\n",
    "        print(\"Current idx: \",str(idx))\n",
    "\n",
    "    if pqwriter:\n",
    "      pqwriter.close()\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "xlWS13v_fWZ0",
    "outputId": "4c18a46c-95af-4cf5-9ba5-889c26f2b555",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing idx nos. from 0 to 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='0'\n",
       "            max='100',\n",
       "            style='width: 75%'\n",
       "        >\n",
       "            0\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "'knn_graph' requires 'torch-cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Boosted Top Jets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mconvert_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgranularity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnew_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 59\u001b[0m, in \u001b[0;36mconvert_to_graph\u001b[0;34m(train_data, start_idx, end_idx, granularity, new_file)\u001b[0m\n\u001b[1;32m     57\u001b[0m feats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((coords[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m],coords[:,\u001b[38;5;241m1\u001b[39m:], pT, d0, dz, Ecal, Hcal, BPIX1, BPIX2, BPIX3), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     58\u001b[0m feats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(feats,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mknn_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m## Create knn graph adjacency matrix\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#print(coords.shape, edge_index.shape, pT.shape, Ecal.shape, Hcal.shape, dz.shape, d0.shape, BPIX1.shape, BPIX2.shape, BPIX3.shape)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#parquet_Dataframe = pd.DataFrame({'coords0':[np.array(coords[:,0].cpu())], 'coords1':[np.array(coords[:,1].cpu())], 'edge_index_from': [np.array(edge_index[0,:].cpu())], 'edge_index_to': [np.array(edge_index[1,:].cpu())], 'pT': [np.array(torch.squeeze(pT).cpu())], 'ECAL':[np.array(torch.squeeze(Ecal).cpu())], 'HCAL':[np.array(torch.squeeze(Hcal).cpu())], 'd0':[np.array(torch.squeeze(d0).cpu())], 'dz':[np.array(torch.squeeze(dz).cpu())], 'BPIX1':[np.array(torch.squeeze(BPIX1).cpu())], 'BPIX2': [np.array(torch.squeeze(BPIX2).cpu())], 'BPIX3': [np.array(torch.squeeze(BPIX3).cpu())], 'y':np.array(train_data[idx]['y']), 'tfrecord': train_data[idx]['tfrecord'], 'm0': train_data[idx]['m0'], 'pT_jet': train_data[idx]['pt']})\u001b[39;00m\n\u001b[1;32m     63\u001b[0m parquet_Dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords0\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords1\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_from\u001b[39m\u001b[38;5;124m'\u001b[39m: [np\u001b[38;5;241m.\u001b[39marray(edge_index[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_to\u001b[39m\u001b[38;5;124m'\u001b[39m: [np\u001b[38;5;241m.\u001b[39marray(edge_index[\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpT\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md0\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdz\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mECAL\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHCAL\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBPIX1\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBPIX2\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBPIX3\u001b[39m\u001b[38;5;124m'\u001b[39m:[np\u001b[38;5;241m.\u001b[39marray(feats[:,\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu())],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m:np\u001b[38;5;241m.\u001b[39marray(train_data[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m: train_data[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm0\u001b[39m\u001b[38;5;124m'\u001b[39m: train_data[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm0\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpT_jet\u001b[39m\u001b[38;5;124m'\u001b[39m: train_data[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m~/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/torch_geometric/nn/pool/__init__.py:167\u001b[0m, in \u001b[0;36mknn_graph\u001b[0;34m(x, k, batch, loop, flow, cosine, num_workers, batch_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_TORCH_CLUSTER_BATCH_SIZE:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn_graph\u001b[49m(x, k, batch, loop, flow, cosine,\n\u001b[1;32m    168\u001b[0m                                    num_workers)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_cluster\u001b[38;5;241m.\u001b[39mknn_graph(x, k, batch, loop, flow, cosine,\n\u001b[1;32m    170\u001b[0m                                num_workers, batch_size)\n",
      "File \u001b[0;32m~/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/torch_geometric/typing.py:81\u001b[0m, in \u001b[0;36mTorchCluster.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-cluster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: 'knn_graph' requires 'torch-cluster'"
     ]
    }
   ],
   "source": [
    "# Boosted Top Jets\n",
    "convert_to_graph(dset_train,0,100,granularity=1,new_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "086c8HGt9jeU",
    "outputId": "0f66a780-68a4-43ef-f1e9-0761c8ac9e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing idx nos. from 326400 to 332800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='332680'\n",
       "            max='332800',\n",
       "            style='width: 75%'\n",
       "        >\n",
       "            332680\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current idx:  326400\n",
      "Current idx:  329600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='332799'\n",
       "            max='332800',\n",
       "            style='width: 75%'\n",
       "        >\n",
       "            332799\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boosted Top Jets\n",
    "convert_to_graph(dset_train,6400*51,6400*52,granularity=1,new_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNSSuPOKA2-s",
    "outputId": "f9640b8a-7c69-429c-dcac-d808233ce32d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_jets': tensor([[0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'm0': tensor([69.3547]),\n",
       " 'pt': tensor([626.9458]),\n",
       " 'tfrecord': ['data_shared/BoostedTop_x1_fixed_tfrecord/BoostedJets_fullSample_x1_file-143'],\n",
       " 'y': tensor([0.])}"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_train[640000-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8C0etrOq5Cx"
   },
   "outputs": [],
   "source": [
    "tp = dset_test[75]['ECAL'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wX7OxCx8v246",
    "outputId": "130a0d79-31f6-48b6-cdb5-6b78f5f792b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_test[75]['ECAL'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWWwHHNuwhvp"
   },
   "outputs": [],
   "source": [
    "tp[-1]-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnuHzkPxxjBP",
    "outputId": "89fd5b6e-1420-4a53-9885-b75ac615e132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0212, 0.0212, 0.0521,  ..., 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PSYBXo4xj2V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyTorch_VEN",
   "language": "python",
   "name": "pytorch_ven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
